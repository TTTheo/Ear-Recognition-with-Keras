{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread_collection\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.utils import np_utils \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def load_data(path):\n",
    "    #creating a collection with the available images\n",
    "    image = imread_collection(path)\n",
    "    image_set = []\n",
    "    for n in image:\n",
    "        n = cv2.cvtColor(n,cv2.COLOR_RGB2GRAY)\n",
    "        image_set.append(n)\n",
    "    return image_set\n",
    "\n",
    "\n",
    "\n",
    "def set_init(dataset, train_set_ratio, valid_set_ratio, test_set_ratio):\n",
    "\n",
    "    \n",
    "    #creating label set for all images\n",
    "    label = np.empty(195*4)\n",
    "    for i in range(195):\n",
    "        label[i*4:i*4+4] = i\n",
    "    label = label.astype(np.int)\n",
    "    print(label.shape)\n",
    "    label = np_utils.to_categorical(label, 195)#transfer to one-hot matrix\n",
    "    \n",
    "    train_num = 780*train_set_ratio\n",
    "    train_num = int(train_num)\n",
    "    valid_num = 780*valid_set_ratio\n",
    "    valid_num = int(valid_num)\n",
    "    test_num = 780*test_set_ratio\n",
    "    test_num = int(test_num)\n",
    "    \n",
    "    train_data = np.empty((train_num,200,200))  \n",
    "    train_label = np.empty((train_num,195))   \n",
    "    valid_data = np.empty((valid_num, 200,200))   \n",
    "    valid_label = np.empty((valid_num,195))   \n",
    "    test_data = np.empty((test_num,200,200))  \n",
    "    test_label = np.empty((test_num,195)) \n",
    "    \n",
    "    x_test_tot = np.empty((valid_num + test_num,200,200))\n",
    "    y_test_tot = np.empty((valid_num + test_num,195))\n",
    "    \n",
    "    train_data, x_test_tot, train_label, y_test_tot = train_test_split(dataset, label, test_size = 1-train_set_ratio)\n",
    "    \n",
    "#     valid_data, test_data, valid_label, test_label = train_test_split(x_test_tot, y_test_tot, test_size = test_set_ratio/(valid_set_ratio + test_set_ratio))\n",
    "    \n",
    "    train_data = np.asarray(train_data)\n",
    "    x_test_tot = np.asarray(x_test_tot);\n",
    "    valid_data = np.asarray(valid_data)\n",
    "    test_data = np.asarray(test_data)\n",
    "#     for i in range(195):\n",
    "#         train_data[i * 2:i * 2 + 2] = image_set[i * 4:i * 4 + 2]\n",
    "#         train_label[i * 2:i * 2 + 2] = label[i * 4:i * 4 + 2]\n",
    "#         valid_data[i] = image_set[i * 4 + 2]\n",
    "#         valid_label[i] = label[i * 4 + 2]\n",
    "#         test_data[i] = image_set[i * 4 + 3]\n",
    "#         test_label[i] = label[i * 4 + 3]\n",
    "    result = [(train_data, train_label), (valid_data, valid_label),(test_data, test_label)]\n",
    "    return result\n",
    "\n",
    "def process_image(image_set, size, margin):\n",
    "    data = []\n",
    "    for n in image_set:\n",
    "        n = n[margin[0]:margin[1], margin[2]:margin[3]]\n",
    "        n = cv2.resize(n,(size,size))\n",
    "        n = n / 255\n",
    "        data.append(n)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = load_data('original/*.jpg')\n",
    "data_final = process_image(data_set, size = 200, margin = [500,2500,500,3500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(780,)\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3944331eac18>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata_final\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_final\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_set_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_set_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_set_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-fdaba761b7d1>\u001b[0m in \u001b[0;36mset_init\u001b[0;34m(dataset, train_set_ratio, valid_set_ratio, test_set_ratio)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test_tot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_tot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtrain_set_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m     \u001b[0mvalid_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalid_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_tot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_tot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_set_ratio\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalid_set_ratio\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mtest_set_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "data_final = set_init(data_final, train_set_ratio = 1, valid_set_ratio = 0, test_set_ratio = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image\n",
    "from keras import regularizers\n",
    "from keras.utils import generic_utils\n",
    "\n",
    "def train(data, batch_size, epochs, nb_filters, pool_size, kernel_size, X_target):\n",
    "    np.random.seed(1337)  # for reproducibility\n",
    "    img_rows, img_cols = 200, 200  # 输入图片样本的宽高\n",
    "    nb_classes = 195  # 分类数目\n",
    "    input_shape = (img_rows, img_cols,1)  # 输入图片的维度\n",
    "\n",
    "    [(train_data, train_label), (valid_data, valid_label),(test_data, test_label)] = data\n",
    "    X_train = X_train[:,:,:,np.newaxis]  # 添加一个维度，代表图片通道。这样数据集共4个维度，样本个数、宽度、高度、通道数\n",
    "    print('样本数据集的维度：', X_train.shape,Y_train.shape)\n",
    "    \n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32,kernel_size,padding = 'same', input_shape=input_shape,strides=1))  # 卷积层1\n",
    "    model.add(Activation('relu'))  \n",
    "    model.add(AveragePooling2D(pool_size,strides=2))  # 池化层  \n",
    "    model.add(Conv2D(64,kernel_size,strides=1))  # 卷积层2\n",
    "    model.add(Activation('relu'))    \n",
    "    model.add(AveragePooling2D(pool_size,strides=2))  # 池化层\n",
    "    model.add(Flatten())  # 拉成一维数据\n",
    "    model.add(Dense(nb_classes)) # 全连接层2, ,kernel_regularizer=regularizers.l2(0.05)\n",
    "    model.add(Activation('softmax'))  # softmax评分\n",
    "\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
    "    # 训练模型\n",
    "    model.fit(X_train, Y_train, batch_size, epochs,verbose=1)\n",
    "    \n",
    "    \n",
    "    y_out = model.predict(X_target)\n",
    "    y_out = y_out.argmax(axis=1)\n",
    "    print('This is person No.%d'%(y_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = [data_set[0]]\n",
    "image = process_image(image, size = 200, margin = [500,2500,500,3500])\n",
    "image = np.asarray(image)\n",
    "\n",
    "image = image[:,:,:,np.newaxis] \n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(data_final, batch_size = 20,epochs = 15, nb_filters = 64, pool_size = 2, kernel_size = 3,X_target = image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
