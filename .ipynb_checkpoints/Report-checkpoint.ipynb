{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Ear Recognition\n",
    "Yifei Feng | U81901533\n",
    "\n",
    "Zehui Jiang | U68975915\n",
    "\n",
    "Guangxing Ren | U072735315"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify your problem\n",
    "**Take a look at your topic and available resources, come up with a problem you think is interesting and worth working on. Give details about why is it a valuable topic and then describe the problem you are going to solve in a precise way.**\n",
    "\n",
    "#AI recognization system has been well implementing these days. A famous commercial example is facing ID by Apple. Before unlocking the device or finish the transaction, a facial scan is being conducted to check the identification of the user.  Another similar area#\n",
    "\n",
    "The process of precisely recognize people by ears also has been getting major attention in recent years. It represents an important step in the biometric research, especially as a complement to face recognition systems which have difficulty in real conditions. This is due to the great variation in shapes, variable lighting conditions, and the changing profile shape which is a planar representation of a complex object. We present an ear recognition system involving a convolutional neural network (CNN)  to identify a person given an input image.\n",
    "\n",
    "There are few methods \n",
    "Data:\n",
    "We are given a set of left ear image from people with different identities. For each ear(each person). Four images are given, we for ears “in the wild” (there is no constraint in the way of taking the photo), two for ear images taken with a “donut device” that serves as a background and somewhat controls lighting.  There are 4*195(individual ear) in the dataset.\n",
    "\n",
    " http://cs-people.bu.edu/wdqin/earImageDataset.zip\n",
    " \n",
    " \n",
    " \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backgroud\n",
    "\n",
    "\n",
    "Find out about and list more than one existing (possible) solution to your problem, make a brief comparison, and evaluation on these methods. Choose one of the existing solutions as a baseline for comparison.  Consider how much time you have and effort might be required to reproduce the result. Be realistic with your goal.\n",
    "\n",
    "\n",
    "We found an existing Face Recognition CNN that applies Convolutional Neural Network. \n",
    "\n",
    "We use kears as our open-source neural-network library.Keras is a high-level API for neural networks. It is written in Python and its biggest advantage is its ability to run on top of state-of-art deep learning libraries/frameworks such as TensorFlow, CNTK or Theano.\n",
    "\n",
    "\n",
    "\n",
    "These are the time distribution we planned for each individual member:\n",
    "\n",
    "Background research:   4 hours\n",
    "Reproducing Baseline: 6 hours\n",
    "Improvement: 5  hours\n",
    "Final Report: 4 hours\n",
    "\n",
    "We don’t want to ignore the importance of background research and report. Since we are given limited time for this complicated project. We want to spend more time on understanding the existing algorithm and application.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Reproducing the baseline:\n",
    "\n",
    "We found an existing Face Recognition CNN  that applies Convolutional Neural Network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.io import imread_collection\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.utils import np_utils \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#loading dataset from directory and resize every picture to 200x200 dmension\n",
    "def load_data(path, size):\n",
    "    #creating a collection with the available images\n",
    "    image = imread_collection(path)\n",
    "    image_set = []\n",
    "    for n in image:\n",
    "        n = cv2.cvtColor(n,cv2.COLOR_RGB2GRAY)\n",
    "        n = cv2.resize(n,(size,size)) \n",
    "        n = n / 255\n",
    "        image_set.append(n)\n",
    "    return image_set \n",
    "    \n",
    "def set_init(dataset, train_set_ratio, valid_set_ratio, test_set_ratio):\n",
    "\n",
    "    \n",
    "    #creating label set for all images\n",
    "    label = np.empty(195*4)\n",
    "    for i in range(195):\n",
    "        label[i*4:i*4+4] = i\n",
    "    label = label.astype(np.int)\n",
    "    label = np_utils.to_categorical(label, 195)#transfer to one-hot matrix\n",
    "    \n",
    "    train_num = 780*train_set_ratio\n",
    "    train_num = int(train_num)\n",
    "    valid_num = 780*valid_set_ratio\n",
    "    valid_num = int(valid_num)\n",
    "    test_num = 780*test_set_ratio\n",
    "    test_num = int(test_num) \n",
    "    \n",
    "    train_data = np.empty((train_num,200,200))  #creating numpy array for different datasets\n",
    "    train_label = np.empty((train_num,195))   \n",
    "    valid_data = np.empty((valid_num, 200,200))   \n",
    "    valid_label = np.empty((valid_num,195))   \n",
    "    test_data = np.empty((test_num,200,200))  \n",
    "    test_label = np.empty((test_num,195)) \n",
    "    \n",
    "    x_test_tot = np.empty((valid_num + test_num,200,200))\n",
    "    y_test_tot = np.empty((valid_num + test_num,195))\n",
    "    \n",
    "    train_data, x_test_tot, train_label, y_test_tot = train_test_split(dataset, label, test_size = 1-train_set_ratio)\n",
    "    \n",
    "    valid_data, test_data, valid_label, test_label = train_test_split(x_test_tot, y_test_tot, test_size = test_set_ratio/(valid_set_ratio + test_set_ratio))\n",
    "    \n",
    "    result = [(train_data, train_label), (valid_data, valid_label),(test_data, test_label)]\n",
    "   \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D,AveragePooling2D\n",
    "from PIL import Image\n",
    "def train(data, batch_size, epochs, nb_filters, pool_size, kernel_size):\n",
    "    np.random.seed(1337)  # for reproducibility\n",
    "    img_rows, img_cols = 200, 200  # 输入图片样本的宽高\n",
    "    nb_classes = 195  # 分类数目\n",
    "    input_shape = (img_rows, img_cols,1)  # 输入图片的维度\n",
    "\n",
    "    [(X_train, Y_train), (X_valid, Y_valid),(X_test, Y_test)] = data\n",
    "\n",
    "    X_train = X_train[:,:,:,np.newaxis]  # 添加一个维度，代表图片通道。这样数据集共4个维度，样本个数、宽度、高度、通道数\n",
    "    X_valid=X_valid[:,:,:,np.newaxis]  # 添加一个维度，代表图片通道。这样数据集共4个维度，样本个数、宽度、高度、通道数\n",
    "    X_test=X_test[:,:,:,np.newaxis]  # 添加一个维度，代表图片通道。这样数据集共4个维度，样本个数、宽度、高度、通道数\n",
    "    print('样本数据集的维度：', X_train.shape,Y_train.shape)\n",
    "    print('测试数据集的维度：', X_test.shape,Y_test.shape)\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(6,kernel_size,input_shape=input_shape,strides=1))  # 卷积层1\n",
    "    model.add(AveragePooling2D(pool_size,strides=2))  # 池化层\n",
    "    model.add(Conv2D(12,kernel_size,strides=1))  # 卷积层2\n",
    "    model.add(AveragePooling2D(pool_size,strides=2))  # 池化层\n",
    "    model.add(Flatten())  # 拉成一维数据\n",
    "    model.add(Dense(nb_classes))  # 全连接层2\n",
    "    model.add(Activation('sigmoid'))  # sigmoid评分\n",
    "\n",
    "    # 编译模型\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
    "    # 训练模型\n",
    "    model.fit(X_train, Y_train, batch_size, epochs,verbose=1, validation_data=(X_valid, Y_valid))\n",
    "    # 评估模型\n",
    "    score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])\n",
    "\n",
    "\n",
    "\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred = y_pred.argmax(axis=1)   # 获取概率最大的分类，获取每行最大值所在的列\n",
    "    for i in range(len(y_pred)):\n",
    "    #     oneimg = X_test[i,:,:,0]*256\n",
    "    #     im = Image.fromarray(oneimg)\n",
    "    #     im.show()\n",
    "        print('第%d个人识别为第%d个人'%(i,y_pred[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background survey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing the baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improvement\n",
    "## 1. Regularization\n",
    "## 2. Augmentation\n",
    "## 3. Crop\n",
    "## 4. k-fold\n",
    "## 5. Dropout\n",
    "## 6. Comprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
